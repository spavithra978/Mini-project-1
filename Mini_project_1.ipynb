{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0q3RTzv5ubrzFNGFWxT34",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spavithra978/Mini-project-1/blob/main/Mini_project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# USGS EARTHQUAKE DATA EXTRACTION\n",
        "# Period: Dec 2020 to Dec 2025 (Monthly)\n",
        "# Schema: Full 26-feature project specification\n",
        "# =========================================================\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from google.colab import files\n",
        "import time\n",
        "\n",
        "BASE_URL = \"https://earthquake.usgs.gov/fdsnws/event/1/query\""
      ],
      "metadata": {
        "id": "m9ZNW6Dhc4WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 1. DATE RANGE (PROJECT REQUIREMENT)\n",
        "# ------------------------------------------------\n",
        "start_date = datetime(2020, 12, 1)\n",
        "end_date   = datetime(2025, 12, 1)\n",
        "\n",
        "current = start_date\n",
        "records = []\n",
        "\n",
        "print(\"Starting data fetch...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBbOz8GRdJEc",
        "outputId": "0844b048-f571-4036-8510-adee2bb2297b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data fetch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 2. MONTH-BY-MONTH LOOP (API SAFE)\n",
        "# ---------------------------------------------------------\n",
        "while current < end_date:\n",
        "    month_start = current.strftime(\"%Y-%m-%d\")\n",
        "    month_end = (current + relativedelta(months=1)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    print(f\"Fetching data: {month_start} → {month_end}\")\n",
        "\n",
        "    params = {\n",
        "        \"format\": \"geojson\",\n",
        "        \"starttime\": month_start,\n",
        "        \"endtime\": month_end,\n",
        "        \"minmagnitude\": 0,\n",
        "        \"limit\": 20000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(BASE_URL, params=params, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        events = response.json().get(\"features\", [])\n",
        "\n",
        "        print(f\"  → Records fetched: {len(events)}\")\n",
        "\n",
        "        for event in events:\n",
        "            prop = event.get(\"properties\", {})\n",
        "            geom = event.get(\"geometry\", {}).get(\"coordinates\", [None, None, None])\n",
        "\n",
        "            records.append({\n",
        "                # 1–3 Identifiers & Time\n",
        "                \"id\": event.get(\"id\"),\n",
        "                \"time\": pd.to_datetime(prop.get(\"time\"), unit=\"ms\", utc=True),\n",
        "                \"updated\": pd.to_datetime(prop.get(\"updated\"), unit=\"ms\", utc=True),\n",
        "\n",
        "                # 4–6 Location\n",
        "                \"latitude\": geom[1],\n",
        "                \"longitude\": geom[0],\n",
        "                \"depth_km\": geom[2],\n",
        "\n",
        "                # 7–8 Magnitude\n",
        "                \"mag\": prop.get(\"mag\"),\n",
        "                \"magType\": prop.get(\"magType\"),\n",
        "\n",
        "                # 9–10 Place & Status\n",
        "                \"place\": prop.get(\"place\"),\n",
        "                \"status\": prop.get(\"status\"),\n",
        "\n",
        "                # 11–13 Tsunami / Significance / Network\n",
        "                \"tsunami\": prop.get(\"tsunami\"),\n",
        "                \"sig\": prop.get(\"sig\"),\n",
        "                \"net\": prop.get(\"net\"),\n",
        "\n",
        "                # 14–17 Quality Metrics\n",
        "                \"nst\": prop.get(\"nst\"),\n",
        "                \"dmin\": prop.get(\"dmin\"),\n",
        "                \"rms\": prop.get(\"rms\"),\n",
        "                \"gap\": prop.get(\"gap\"),\n",
        "\n",
        "                # 18–20 Error Metrics\n",
        "                \"magError\": prop.get(\"magError\"),\n",
        "                \"depthError\": prop.get(\"depthError\"),\n",
        "                \"magNst\": prop.get(\"magNst\"),\n",
        "\n",
        "                # 21–22 Source Information\n",
        "                \"locationSource\": prop.get(\"locationSource\"),\n",
        "                \"magSource\": prop.get(\"magSource\"),\n",
        "\n",
        "                # 23–25 References\n",
        "                \"types\": prop.get(\"types\"),\n",
        "                \"ids\": prop.get(\"ids\"),\n",
        "                \"sources\": prop.get(\"sources\"),\n",
        "\n",
        "                # 26 Event Type\n",
        "                \"type\": prop.get(\"type\")\n",
        "            })\n",
        "\n",
        "        time.sleep(1)  # Prevent API throttling\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Failed for {month_start}: {e}\")\n",
        "\n",
        "    current += relativedelta(months=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh2mHjgzdZVj",
        "outputId": "2cb053c9-dead-4401-8442-ff376db50698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data: 2020-12-01 → 2021-01-01\n",
            "  → Records fetched: 15202\n",
            "Fetching data: 2021-01-01 → 2021-02-01\n",
            "  → Records fetched: 14996\n",
            "Fetching data: 2021-02-01 → 2021-03-01\n",
            "  → Records fetched: 11538\n",
            "Fetching data: 2021-03-01 → 2021-04-01\n",
            "  → Records fetched: 13247\n",
            "Fetching data: 2021-04-01 → 2021-05-01\n",
            "  → Records fetched: 12396\n",
            "Fetching data: 2021-05-01 → 2021-06-01\n",
            "  → Records fetched: 11388\n",
            "Fetching data: 2021-06-01 → 2021-07-01\n",
            "  → Records fetched: 13705\n",
            "Fetching data: 2021-07-01 → 2021-08-01\n",
            "  → Records fetched: 17285\n",
            "Fetching data: 2021-08-01 → 2021-09-01\n",
            "  → Records fetched: 16284\n",
            "Fetching data: 2021-09-01 → 2021-10-01\n",
            "  → Records fetched: 13272\n",
            "Fetching data: 2021-10-01 → 2021-11-01\n",
            "  → Records fetched: 12141\n",
            "Fetching data: 2021-11-01 → 2021-12-01\n",
            "  → Records fetched: 11299\n",
            "Fetching data: 2021-12-01 → 2022-01-01\n",
            "  → Records fetched: 11165\n",
            "Fetching data: 2022-01-01 → 2022-02-01\n",
            "  → Records fetched: 12471\n",
            "Fetching data: 2022-02-01 → 2022-03-01\n",
            "  → Records fetched: 11489\n",
            "Fetching data: 2022-03-01 → 2022-04-01\n",
            "  → Records fetched: 12387\n",
            "Fetching data: 2022-04-01 → 2022-05-01\n",
            "  → Records fetched: 12002\n",
            "Fetching data: 2022-05-01 → 2022-06-01\n",
            "  → Records fetched: 11409\n",
            "Fetching data: 2022-06-01 → 2022-07-01\n",
            "  → Records fetched: 11330\n",
            "Fetching data: 2022-07-01 → 2022-08-01\n",
            "  → Records fetched: 11862\n",
            "Fetching data: 2022-08-01 → 2022-09-01\n",
            "  → Records fetched: 12590\n",
            "Fetching data: 2022-09-01 → 2022-10-01\n",
            "  → Records fetched: 12495\n",
            "Fetching data: 2022-10-01 → 2022-11-01\n",
            "  → Records fetched: 12496\n",
            "Fetching data: 2022-11-01 → 2022-12-01\n",
            "  → Records fetched: 12219\n",
            "Fetching data: 2022-12-01 → 2023-01-01\n",
            "  → Records fetched: 12251\n",
            "Fetching data: 2023-01-01 → 2023-02-01\n",
            "  → Records fetched: 11632\n",
            "Fetching data: 2023-02-01 → 2023-03-01\n",
            "  → Records fetched: 10939\n",
            "Fetching data: 2023-03-01 → 2023-04-01\n",
            "  → Records fetched: 15257\n",
            "Fetching data: 2023-04-01 → 2023-05-01\n",
            "  → Records fetched: 12503\n",
            "Fetching data: 2023-05-01 → 2023-06-01\n",
            "  → Records fetched: 12082\n",
            "Fetching data: 2023-06-01 → 2023-07-01\n",
            "  → Records fetched: 11456\n",
            "Fetching data: 2023-07-01 → 2023-08-01\n",
            "  → Records fetched: 12116\n",
            "Fetching data: 2023-08-01 → 2023-09-01\n",
            "  → Records fetched: 12219\n",
            "Fetching data: 2023-09-01 → 2023-10-01\n",
            "  → Records fetched: 10778\n",
            "Fetching data: 2023-10-01 → 2023-11-01\n",
            "  → Records fetched: 11571\n",
            "Fetching data: 2023-11-01 → 2023-12-01\n",
            "  → Records fetched: 10895\n",
            "Fetching data: 2023-12-01 → 2024-01-01\n",
            "  → Records fetched: 12130\n",
            "Fetching data: 2024-01-01 → 2024-02-01\n",
            "  → Records fetched: 12043\n",
            "Fetching data: 2024-02-01 → 2024-03-01\n",
            "  → Records fetched: 12754\n",
            "Fetching data: 2024-03-01 → 2024-04-01\n",
            "  → Records fetched: 11814\n",
            "Fetching data: 2024-04-01 → 2024-05-01\n",
            "  → Records fetched: 12417\n",
            "Fetching data: 2024-05-01 → 2024-06-01\n",
            "  → Records fetched: 12177\n",
            "Fetching data: 2024-06-01 → 2024-07-01\n",
            "  → Records fetched: 12127\n",
            "Fetching data: 2024-07-01 → 2024-08-01\n",
            "  → Records fetched: 12483\n",
            "Fetching data: 2024-08-01 → 2024-09-01\n",
            "  → Records fetched: 12341\n",
            "Fetching data: 2024-09-01 → 2024-10-01\n",
            "  → Records fetched: 11567\n",
            "Fetching data: 2024-10-01 → 2024-11-01\n",
            "  → Records fetched: 11118\n",
            "Fetching data: 2024-11-01 → 2024-12-01\n",
            "  → Records fetched: 9187\n",
            "Fetching data: 2024-12-01 → 2025-01-01\n",
            "  → Records fetched: 11987\n",
            "Fetching data: 2025-01-01 → 2025-02-01\n",
            "  → Records fetched: 10761\n",
            "Fetching data: 2025-02-01 → 2025-03-01\n",
            "  → Records fetched: 10083\n",
            "Fetching data: 2025-03-01 → 2025-04-01\n",
            "  → Records fetched: 10941\n",
            "Fetching data: 2025-04-01 → 2025-05-01\n",
            "  → Records fetched: 10451\n",
            "Fetching data: 2025-05-01 → 2025-06-01\n",
            "  → Records fetched: 9525\n",
            "Fetching data: 2025-06-01 → 2025-07-01\n",
            "  → Records fetched: 9956\n",
            "Fetching data: 2025-07-01 → 2025-08-01\n",
            "  → Records fetched: 15711\n",
            "Fetching data: 2025-08-01 → 2025-09-01\n",
            "  → Records fetched: 11766\n",
            "Fetching data: 2025-09-01 → 2025-10-01\n",
            "  → Records fetched: 10419\n",
            "Fetching data: 2025-10-01 → 2025-11-01\n",
            "  → Records fetched: 8412\n",
            "Fetching data: 2025-11-01 → 2025-12-01\n",
            "  → Records fetched: 8735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 3. CREATE DATAFRAME\n",
        "# ---------------------------------------------------------\n",
        "df = pd.DataFrame(records)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. DERIVED TIME FEATURES (PROJECT REQUIREMENT)\n",
        "# ---------------------------------------------------------\n",
        "df[\"year\"] = df[\"time\"].dt.year\n",
        "df[\"month\"] = df[\"time\"].dt.month\n",
        "df[\"day\"] = df[\"time\"].dt.day\n",
        "df[\"hour\"] = df[\"time\"].dt.hour\n",
        "df[\"day_of_week\"] = df[\"time\"].dt.day_name()\n"
      ],
      "metadata": {
        "id": "fk0X3zBhfQnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 5. DATA CLEANING\n",
        "# ---------------------------------------------------------\n",
        "numeric_cols = [\n",
        "    \"mag\", \"depth_km\", \"nst\", \"dmin\", \"rms\",\n",
        "    \"gap\", \"magError\", \"depthError\", \"magNst\", \"sig\"\n",
        "]\n",
        "\n",
        "for col in numeric_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "df[\"tsunami\"] = df[\"tsunami\"].fillna(0).astype(int)\n",
        "df[\"status\"] = df[\"status\"].fillna(\"unknown\")\n",
        "df[\"magType\"] = df[\"magType\"].fillna(\"unknown\")\n",
        "df[\"net\"] = df[\"net\"].fillna(\"unknown\")\n",
        "df[\"type\"] = df[\"type\"].fillna(\"unknown\")"
      ],
      "metadata": {
        "id": "Hd55r74wfs1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 6. SAVE CSV\n",
        "# ---------------------------------------------------------\n",
        "csv_name = \"earthquakes_5years_full_schema.csv\"\n",
        "df.to_csv(csv_name, index=False)\n",
        "\n",
        "print(\"========================================\")\n",
        "print(\"CSV CREATED SUCCESSFULLY\")\n",
        "print(\"File:\", csv_name)\n",
        "print(\"Rows:\", len(df))\n",
        "print(\"Columns:\", len(df.columns))\n",
        "print(\"========================================\")\n",
        "\n",
        "files.download(csv_name)"
      ],
      "metadata": {
        "id": "DN8QvHJIf2uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CP0_GVS7ga2B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}